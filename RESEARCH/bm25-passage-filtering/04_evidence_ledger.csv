claim_id,claim,confidence,type,source_ids,independence,status,notes
CL01,"bm25s is up to 500x faster than rank_bm25 on large corpora",HIGH,C1,"S01,S03",INDEPENDENT (bm25s benchmarks + HuggingFace blog independent from rank_bm25 repo),VERIFIED,"Speed advantage irrelevant for <100 doc corpus"
CL02,"rank_bm25 requires only numpy as dependency",HIGH,C1,"S02,S03",INDEPENDENT (PyPI listing + HuggingFace comparison),VERIFIED,"numpy is 18MB"
CL03,"BM25 Okapi default parameters are k1=1.5 b=0.75",HIGH,C1,"S02,S12",INDEPENDENT (rank_bm25 source + Elastic blog),VERIFIED,"Standard since original Okapi system"
CL04,"200-token chunks maximize precision for pre-filtering",MEDIUM,C1,"S05,S04",INDEPENDENT (Chroma evaluation + NVIDIA benchmark),VERIFIED,"Chroma: 200 tokens = 7.0% precision vs 3.6% at 400; NVIDIA: 512-1024 best for retrieval but different context"
CL05,"15% overlap performed best in NVIDIA benchmark",MEDIUM,C2,S04,SINGLE SOURCE,VERIFIED,"Specific to FinanceBench with 1024-token chunks"
CL06,"OpenAI default of 800 tokens + 400 overlap produced notably weak results",HIGH,C1,"S05",SINGLE SOURCE (Chroma only),VERIFIED,"Direct experimental result from Chroma evaluation"
CL07,"Anthropic contextual BM25+embeddings reduced failure rate by 49%",HIGH,C1,S07,SINGLE SOURCE (Anthropic blog),VERIFIED,"Primary source from Anthropic's own benchmark"
CL08,"Anthropic found top-20 most performant vs top-5 and top-10",HIGH,C1,S07,SINGLE SOURCE (Anthropic blog),VERIFIED,"Their specific experimental setup"
CL09,"BM25 achieves NDCG@10 of 0.434 average on BEIR benchmark",HIGH,C1,S08,AUTHORITATIVE (NeurIPS benchmark paper),VERIFIED,"BEIR is the standard IR benchmark"
CL10,"LangChain BM25Retriever defaults to K=4 with text.split() tokenizer",HIGH,C1,"S10,search results",CORROBORATED by source code references,VERIFIED,"Confirmed from API docs"
CL11,"BM25 fails on vocabulary mismatch between query and passage terms",HIGH,C1,"S13,S16",INDEPENDENT (NAACL paper + Emergent Mind survey),VERIFIED,"Well-established limitation"
CL12,"Pure vector search outperformed hybrid on academic abstracts (84% vs 78%)",MEDIUM,C2,S14,SINGLE SOURCE (Dataquest blog),PARTIALLY VERIFIED,"Specific to one experiment; illustrates failure mode"
CL13,"BM25 core algorithm implementable in ~40-60 lines of Python",HIGH,C1,"S02,implementation verification",VERIFIED by examining rank_bm25 source code,VERIFIED,"Confirmed: the scoring formula is simple math"
CL14,"Crawl4AI uses two-pass filtering: structural pruning then BM25 scoring",MEDIUM,C2,S09,SINGLE SOURCE,VERIFIED,"Architecture documented in Crawl4AI docs"
CL15,"LangChain recommends BM25+ for short passages in RAG workflows",MEDIUM,C2,S10,SINGLE SOURCE (LangChain docs),VERIFIED,"Documented recommendation"
